# -*- coding: utf-8 -*-
"""Mavoix Solutions assgnment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13cWlOUCzAKSSyE9vx9WVwRSc5Rs5agLY
"""

import pandas as pd

#Use to import the file into google Colab drive
from google.colab import files 
#Use to import io, which opens the file from the Colab drive
import io

from sklearn.model_selection import train_test_split

#Load the Drive helper and mount 
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_excel('/content/drive/My Drive/Colab Notebooks/mavoix_ml_sample_dataset.xlsx')

#average of all columns related to Deep Learning
df_deep= df.iloc[:, 2:5].mean(axis=1)

print(df_deep)

#average of all columns related to Web Development
df_web= df.iloc[:, [3,5,6,7,8,9, 11,12,13,14,15]].mean(axis=1)

print(df_web)

df['deep']= df.iloc[:, [2,4]].mean(axis=1)

df['web']= df.iloc[:, [3,5,6,7,8,9, 11,12,13,14,15]].mean(axis=1)

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans, SpectralClustering
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_samples, silhouette_score

df.iloc[:, -2:]

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

options= ['Machine Learning', 'Neural Networks', 'Python', 'Deep Learning', 'Data Analytics', 'Computer Vision', 'Natural Language Processing (NLP)', 'Artifical Intelligence' ]
df['web_score']= df.loc[:,'Other skills'].isin(options)

df.iloc[:,-1]

#converting all marks of ug into /100
lst=[]
for x in df['Performance_UG']:
    #print(type(x))
    if type(x)==float:
        lst.append(0)
    elif(type(x)!=float):
        marks=x.split('/')
        if (float(marks[1])!= 100):
            marks[0]= float(marks[0])/float(marks[1])* 100
        lst.append(marks[0])
        #print(marks[0])
#print (lst)  
df['norm_ug'] = pd.DataFrame(lst)

df['norm_ug']

#converting all marks of 12 into /100
lst=[]
for x in df['Performance_12']:
    #print(type(x))
    if type(x)==float:
        lst.append(0)
    elif(type(x)!=float):
        marks=x.split('/')
        if (float(marks[1])<= 10):
            marks[0]= float(marks[0])/float(marks[1])* 100
        lst.append(marks[0])
        #print(marks[0])
#print (lst)  
df['norm_12'] = pd.DataFrame(lst)

df['norm_12']

#converting all marks of 10 into /100
lst=[]
for x in df['Performance_10']:
    #print(type(x))
    if type(x)==float:
        lst.append(0)
    elif(type(x)!=float):
        marks=x.split('/')
        if (float(marks[1])<= 10):
            marks[0]= float(marks[0])/float(marks[1])* 100
        lst.append(marks[0])
        #print(marks[0])
#print (lst)  
df['norm_10'] = pd.DataFrame(lst)

df['norm_10']

stream_sorted = df["Stream"].unique()
degree_sorted = df["Degree"].unique()
city_sorted = df["Current City"].unique()

stream_map = dict([(y,x+1) for x,y in enumerate(stream_sorted)])
degree_map = dict([(y,x+1) for x,y in enumerate(degree_sorted)])
city_map= dict([(y,x+1) for x,y in enumerate(city_sorted)])

# print(stream_map)
new_stream=[]
new_degree=[]
new_performance=[]
new_city=[]
#un_skill=[]

for x in df["Stream"]:
    new_stream.append(stream_map[x])

for x in df["Degree"]:
    new_degree.append(degree_map[x])

for x in df["Current City"]:
    new_city.append(city_map[x])


for x in df["Performance_PG"]:
    if type(x)==float:
        new_performance.append(0)
    else:
        new_performance.append(1)

#handling 'other skilss'

ml_option=['Python','Artifical Intelligence','Machine Learning','Image Processing','Data Analytics','Statistical Modeling','Deep Learning','R Programming','Neural Networks','Computer Vision','Google Analytics']
web_option=['Angular 2.0','AngularJS','JavaScript','CSS','Django','Node.js','PHP','LARAVEL','Angular 7.0','jQuery','XML','HTML','ReactJS']

new_skill_ml=[]
new_skill_web=[]
label=[]

for x in df["Other skills"]:
    if not type(x)==float:
        if ',' in x:
            count_ml=0
            count_web=0            
            for y in x.split(','):
                y=y.strip()
                if y in ml_option:
                    count_ml=count_ml+1
                if y in web_option:
                    count_web=count_web+1
                
            if count_ml>count_web:
                label.append(1)
            else:
                label.append(0)

            new_skill_ml.append(count_ml)
            new_skill_web.append(count_web)
        else:
            x=x.strip()
            if x in ml_option:
                label.append(1)
            else:
                label.append(0)
    else:
        label.append(0)

#print(new_skill_ml)
#print(new_skill_web)

df['new_stream']= pd.DataFrame(new_stream)
df['new_degree']= pd.DataFrame(new_degree)
df['new_performance_pg']= pd.DataFrame(new_performance)
df['new_city']= pd.DataFrame(new_city)
df['new_skill_ml']= pd.DataFrame(new_skill_ml)
df['new_skill_web']= pd.DataFrame(new_skill_web)
df['label']= pd.DataFrame(label)

df

#1 
x = df.iloc[:, -10:-3].values
y= df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

print(y_pred)

print(len(y_test))

import sklearn.metrics as metrics
print("Accuracy=",metrics.accuracy_score(y_test, y_pred))

k_range = range(1, 26)
scores = []
# looping through the range 1 to 26 different k values
# appending the scores in the dictionary
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    scores.append(metrics.accuracy_score(y_test, y_pred))
print(scores)

from sklearn.ensemble import ExtraTreesClassifier
model = ExtraTreesClassifier()
model.fit(X_train, y_train)
# display the relative importance of each attribute
print(model.feature_importances_)

#2
x = df.iloc[:, [-10, -9, -7, -6, -4]].values
y= df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)


k_range = range(1, 26)
scores = []
# looping through the range 1 to 26 different k values
# appending the scores in the dictionary
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    scores.append(metrics.accuracy_score(y_test, y_pred))
print(scores)

model = ExtraTreesClassifier()
model.fit(X_train, y_train)
# display the relative importance of each attribute
print(model.feature_importances_)
